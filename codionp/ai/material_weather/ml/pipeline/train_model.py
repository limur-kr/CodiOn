# ai/data/material_weather/train_model.py
# ëª¨ë¸ë§ í•™ìŠµ ì½”ë“œ

import os
import random

import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
# âœ… ê³ ë„í™” 1: Tree ëª¨ë¸ ë° ê²€ì¦ ë„êµ¬ import
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split, learning_curve, cross_val_score

# --- 1. í•œê¸€ í°íŠ¸ ì„¤ì • (ê¹¨ì§ ë°©ì§€) ---
# OSì— ë”°ë¼ í°íŠ¸ ì„¤ì •ì´ ë‹¤ë¥´ì§€ë§Œ, ì˜ì–´ë¡œ ì¶œë ¥ë˜ê²Œ ì„¤ì •í•˜ê±°ë‚˜ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False

# --- 1. ë°ì´í„° ìƒì„± (ì²´ê°ì˜¨ë„ & ê°•ìˆ˜í™•ë¥  ì ìš©) ---
# X(ì…ë ¥): [ì²´ê°ì˜¨ë„, ìŠµë„, ê°•ìˆ˜í™•ë¥ , ë³´ì˜¨ì„±, í†µê¸°ì„±, ë°©ìˆ˜ì„±]
# y(ì •ë‹µ): 0(ë¶€ì í•©) or 1(ì í•©)

print("ğŸ“Š ë°ì´í„° ìƒì„± ì¤‘...")
data = []
for _ in range(50000):  # ë°ì´í„° 5000ê°œë¡œ ì¦ê°€
    temp = random.uniform(-10, 35)
    feels_like = temp + random.uniform(-5, 3)
    humidity = random.uniform(20, 90)
    precip_prob = random.randint(0, 100)

    warmth = random.randint(1, 5)
    breathability = random.randint(1, 5)
    water_res = random.randint(1, 5)

    # --- ì •ë‹µ ìƒì„± ê·œì¹™ (ì„ ìƒë‹˜) ---
    score = 0
    # ì²´ê°ì˜¨ë„ ê·œì¹™
    if feels_like < 10:
        score += warmth * 30  # ê°€ì¤‘ì¹˜ ì¦ê°€
    elif feels_like > 25:
        score -= warmth * 20
        score += breathability * 20
    else:
        score += (3 - abs(warmth - 3)) * 10

        # ìŠµë„/ê°•ìˆ˜ ê·œì¹™
    if humidity > 70: score += breathability * 15
    if precip_prob > 30:
        rain_risk = precip_prob / 100.0
        if water_res < 3:
            score -= 60 * rain_risk  # ë²Œì  ê°•í™”
        else:
            score += water_res * 25 * rain_risk

    # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€
    final_score = score + random.uniform(-5, 5)

    # 0(ë¶€ì í•©) vs 1(ì í•©) ê¸°ì¤€
    label = 1 if final_score > 60 else 0

    data.append([feels_like, humidity, precip_prob, warmth, breathability, water_res, label])

df = pd.DataFrame(data,
                  columns=['feels_like', 'humidity', 'precip_prob', 'warmth', 'breathability', 'water_res', 'label'])

# --- 2. ê²€ì¦ ì¤€ë¹„ (Train/Test Split) ---
# ì „ì²´ ë°ì´í„°ì˜ 80%ëŠ” í•™ìŠµì— ì“°ê³ , 20%ëŠ” ë‚˜ì¤‘ì— "ì§„ì§œ ë§ë‚˜?" í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ìˆ¨ê²¨ë‘ 
X = df[['feels_like', 'humidity', 'precip_prob', 'warmth', 'breathability', 'water_res']]
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 3. ëª¨ë¸ í•™ìŠµ (Random Forest) ---
print("ğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ ì¤‘...")
# n_estimators=100: ë‚˜ë¬´ 100ê·¸ë£¨ ì‹¬ê¸°
model = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)
model.fit(X_train, y_train)

# --- 4. ê²€ì¦ ë° í‰ê°€ (Verification) ---
# ìˆ¨ê²¨ë‘” 20% ë°ì´í„°(X_test)ë¡œ ì‹œí—˜ ë³´ê¸°
y_pred = model.predict(X_test)
print("\n" + "=" * 40)
print("ğŸ“¢ [1] ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸")
print("=" * 40)
print(classification_report(y_test, y_pred, target_names=['ë¶€ì í•©(0)', 'ì í•©(1)']))

# --- 5. [ê²€ì¦ 2] êµì°¨ ê²€ì¦ (Cross Validation) ---
# ë°ì´í„°ë¥¼ 5ë“±ë¶„í•´ì„œ 5ë²ˆ ì‹œí—˜ ë´„ -> í‰ê·  ì ìˆ˜ê°€ ì§„ì§œ ì‹¤ë ¥
scores = cross_val_score(model, X, y, cv=5)
print("=" * 40)
print("ğŸ“¢ [2] êµì°¨ ê²€ì¦ (ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸)")
print(f"   - 5ë²ˆ í…ŒìŠ¤íŠ¸ ì ìˆ˜: {scores}")
print(f"   - âœ… ìµœì¢… í‰ê·  ì‹ ë¢°ë„: {scores.mean() * 100:.2f}% (Â±{scores.std() * 100:.2f}%)")
print("=" * 40)

# âœ… íŠ¹ì„± ì¤‘ìš”ë„ (Feature Importance) - ê²€ì¦ì˜ í•µì‹¬!
# ëª¨ë¸ì´ ì–´ë–¤ ì •ë³´ë¥¼ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë´¤ëŠ”ì§€ ì•Œë ¤ì¤Œ
importances = model.feature_importances_
feature_names = X.columns
sorted_idx = np.argsort(importances)[::-1]

print("ğŸ” ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ìƒê°í•œ ìš”ì†Œ (Top 3):")
for i in range(3):
    print(f"{i + 1}ìœ„: {feature_names[sorted_idx[i]]} ({importances[sorted_idx[i]] * 100:.1f}%)")
print("-" * 30)

# --- 6. ì €ì¥ ê²½ë¡œ ì„¤ì • ---
current_dir = os.path.dirname(os.path.abspath(__file__))
artifacts_dir = os.path.join(current_dir, "..", "artifacts")
os.makedirs(artifacts_dir, exist_ok=True)

# ëª¨ë¸ ì €ì¥
joblib.dump(model, os.path.join(artifacts_dir, "weather_material_model.pkl"))
print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model}")

# --- 7. [ê²€ì¦ 3] í•™ìŠµ ê³¡ì„  (Learning Curve) ì‹œê°í™” ---
# ë”¥ëŸ¬ë‹ì˜ Loss Curve ëŒ€ìš©. ë°ì´í„°ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§€ëŠ”ì§€ í™•ì¸
print("\nğŸ–¼ï¸ [3] í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ ìƒì„± ì¤‘...")

train_sizes, train_scores, valid_scores = learning_curve(
    model, X, y, cv=5, scoring='accuracy',
    train_sizes=np.linspace(0.1, 1.0, 5)  # ë°ì´í„° 10% ~ 100% ì“¸ ë•Œ ì ìˆ˜ ë³€í™”
)

train_mean = np.mean(train_scores, axis=1)
valid_mean = np.mean(valid_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color="r", label="Training Score")  # í›ˆë ¨ ì ìˆ˜
plt.plot(train_sizes, valid_mean, 'o-', color="g", label="Validation Score")  # ê²€ì¦ ì ìˆ˜ (ì¤‘ìš”!)

plt.title("Learning Curve (Is the model overfitting?)")
plt.xlabel("Training Examples (Data Count)")
plt.ylabel("Accuracy Score")
plt.legend(loc="best")
plt.grid()

save_path = os.path.join(artifacts_dir, "learning_curve.png")
plt.savefig(save_path)
print(f"   -> learning_curve.png ì €ì¥ë¨: {save_path}")

print("\nâœ¨ ëª¨ë“  ê²€ì¦ ì™„ë£Œ!")

# print("ğŸ–¼ï¸ ì‹œê°í™” ìë£Œ ìƒì„± ì¤‘...")
#
# # 1. íŠ¹ì„± ì¤‘ìš”ë„ (Feature Importance)
# plt.figure(figsize=(10, 6))
# importances = model.feature_importances_
# indices = np.argsort(importances)[::-1]
# sns.barplot(x=importances[indices], y=X.columns[indices], palette="viridis")
# plt.title("Feature Importance (What matters most?)")
# plt.xlabel("Importance Score")
# plt.tight_layout()
# plt.savefig(os.path.join(artifacts_dir, "feature_importance.png"))
# print("   -> feature_importance.png ì €ì¥ë¨")
#
# # 2. ì˜¤ì°¨ í–‰ë ¬ (Confusion Matrix)
# plt.figure(figsize=(6, 5))
# cm = confusion_matrix(y_test, y_pred)
# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
#             xticklabels=['Not Suitable', 'Suitable'],
#             yticklabels=['Not Suitable', 'Suitable'])
# plt.title("Confusion Matrix")
# plt.ylabel("Actual Label")
# plt.xlabel("Predicted Label")
# plt.tight_layout()
# plt.savefig(os.path.join(artifacts_dir, "confusion_matrix.png"))
# print("   -> confusion_matrix.png ì €ì¥ë¨")
#
# # 3. ì˜ì‚¬ê²°ì • ë‚˜ë¬´ í•˜ë‚˜ ëœ¯ì–´ë³´ê¸° (Tree Visualization)
# # ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ë‚˜ë¬´ 100ê°œ ì¤‘ ì²« ë²ˆì§¸ ë‚˜ë¬´ë§Œ ì‹œê°í™”í•´ì„œ ë¡œì§ í™•ì¸
# plt.figure(figsize=(20, 10))
# plot_tree(model.estimators_[0],
#           feature_names=X.columns,
#           class_names=['Not Suitable', 'Suitable'],
#           filled=True, rounded=True, max_depth=3, fontsize=10)
# plt.title("Single Tree Logic (Depth 3)")
# plt.savefig(os.path.join(artifacts_dir, "tree_logic.png"))
# print("   -> tree_logic.png ì €ì¥ë¨")
#
# print("âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
