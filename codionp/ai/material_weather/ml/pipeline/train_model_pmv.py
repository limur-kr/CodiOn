# ai/ml_api/ml/pipeline/train_model_pmv.py
# Zhang 2020, Schiavon 2025 ê¸°ë°˜ PMV ëª¨ë¸ í•™ìŠµ

import os
import math
import random
import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# LightGBM & Scikit-learn
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split, learning_curve, cross_val_score

from optuna.samplers import TPESampler

random.seed(42)
np.random.seed(42)

try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    print("âš ï¸ Optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")

# --- 1. í™˜ê²½ ì„¤ì • ---
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False

# [ê¸°ì¤€í‘œ]
DEFAULT_MET = 1.5  # í™œë™ëŸ‰ (ê±·ê¸°/í†µí•™ ê¸°ì¤€)


# --- 2. PMV ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ---
def calculate_pmv_standard(ta, tr, vel, rh, met, clo, wme=0):
    """í‘œì¤€ ISO 7730 PMV ê³„ì‚°ì‹ (Overflow ë°©ì§€ ì ìš©)"""
    try:
        pa = rh * 10 * math.exp(16.6536 - 4030.183 / (ta + 235))
    except Exception:
        return 999  # ì—ëŸ¬ ë°œìƒ ì‹œ 999 ë¦¬í„´

    icl = 0.155 * clo
    m = met * 58.15
    w = wme * 58.15
    mw = m - w
    if icl <= 0.078:
        fcl = 1 + 1.29 * icl
    else:
        fcl = 1.05 + 0.645 * icl

    # ì—´í‰í˜• ë°˜ë³µ ê³„ì‚°
    tcl = ta
    for _ in range(10):
        try:
            hc = 12.1 * math.sqrt(vel)
            if hc < 2.38 * abs(tcl - ta) ** 0.25: hc = 2.38 * abs(tcl - ta) ** 0.25

            # [í•µì‹¬ ìˆ˜ì •] ê³„ì‚° í­ë°œ(Overflow) ê°ì§€ êµ¬ê°„ì„ tryë¡œ ê°ì‹¸ê¸°
            tcl_new = 35.7 - 0.028 * mw - icl * (
                    3.96 * 10 ** -8 * fcl * ((tcl + 273) ** 4 - (tr + 273) ** 4) + fcl * hc * (tcl - ta))

            tcl = (tcl + tcl_new) / 2
        except OverflowError:
            return 999  # ê³„ì‚° ì¤‘ ìˆ«ìê°€ ë„ˆë¬´ ì»¤ì§€ë©´ ì¦‰ì‹œ ì¤‘ë‹¨

    # PMV ìµœì¢… ì‚°ì¶œ
    try:
        ts = 0.303 * math.exp(-0.036 * m) + 0.028
        pmv = ts * (mw - 3.05 * 0.001 * (5733 - 6.99 * mw - pa) - 0.42 * (mw - 58.15)
                    - 1.7 * 10 ** -5 * m * (5867 - pa) - 0.0014 * m * (34 - ta)
                    - 3.96 * 10 ** -8 * fcl * ((tcl + 273) ** 4 - (tr + 273) ** 4) - fcl * hc * (tcl - ta))
    except Exception:
        return 999

    return pmv


def get_corrected_pmv(raw_pmv, vel):
    """ë…¼ë¬¸ ê¸°ë°˜ PMV í¸í–¥ ë³´ì • (Zhang 2020, Schiavon 2025)"""
    if raw_pmv == 999: return 999  # ì—ëŸ¬ ê°’ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬

    corrected_pmv = raw_pmv
    # 1. ì¤‘ë¦½ì—ì„œ ë©€ì–´ì§ˆìˆ˜ë¡ ê³¼ëŒ€í‰ê°€ ê²½í–¥ ì™„í™” (Damping)
    if abs(raw_pmv) > 0.5:
        corrected_pmv = raw_pmv * 0.8
    # 2. ê°•í’ ì‹œ ì¶”ìœ„ ê³¼ëŒ€í‰ê°€ ë³´ì •
    if vel > 0.2 and raw_pmv < 0:
        corrected_pmv += 0.2
    return corrected_pmv


# --- 3. ë°ì´í„° ìƒì„± (Data Generation) ---
print("ğŸ§ª [Level 5] ISO 7730 + ë…¼ë¬¸ ë³´ì • ê¸°ë°˜ ë°ì´í„° 10ë§Œê°œ ìƒì„± ì¤‘...")
data = []

for _ in range(100000):
    # ë‚ ì”¨
    temp = random.uniform(-10, 35)
    humidity = random.uniform(20, 95)
    wind_speed = random.uniform(0.1, 10)

    # ì¼êµì°¨ (API temp_min/max ì‹œë®¬ë ˆì´ì…˜)
    if 10 <= temp <= 25:
        temp_diff = random.uniform(5, 15)
    else:
        temp_diff = random.uniform(2, 8)

    # ì†Œì¬
    warmth = random.randint(1, 5)
    fabric_clo_map = {1: 0.15, 2: 0.4, 3: 0.7, 4: 1.0, 5: 1.5}
    base_clo = fabric_clo_map[warmth]
    fabric_clo = base_clo * random.uniform(0.9, 1.1)  # ë³´ì˜¨ë ¥ Â±10% ë³€ë™
    breathability = random.randint(1, 5)
    water_res = random.randint(1, 5)
    precip_prob = random.randint(0, 100)

    # ë¡œì§ íŒë³„
    raw_pmv = calculate_pmv_standard(temp, temp, wind_speed, humidity, DEFAULT_MET, fabric_clo)

    # ì´ìƒì¹˜ ì œê±°
    if raw_pmv == 999:
        continue


    final_pmv = get_corrected_pmv(raw_pmv, wind_speed)
    is_suitable = True

    # (A) ì—´ì  ì¾Œì ì„± (ë³´ì •ëœ PMV ê¸°ì¤€ì—ì„œ ë…¸ì´ì¦ˆ ì¶”ê°€)
    personal_tolerance = 0.8 + random.uniform(-0.2, 0.2)

    if final_pmv < -personal_tolerance or final_pmv > personal_tolerance:
        is_suitable = False

    # (B) ì¼êµì°¨ ë³´ì •
    if temp_diff >= 10:
        if warmth == 1 or warmth == 5: is_suitable = False

    # (C) ë¬¼ë¦¬ì  ì œì•½
    if humidity > 80 and breathability < 3: is_suitable = False
    if precip_prob > 50 and water_res < 3: is_suitable = False

    dist = abs(final_pmv)  # 0ì—ì„œ ì–¼ë§ˆë‚˜ ë¨¼ê°€?
    score = 100 - (dist * 33.3)  # PMV 1ë‹¹ ì•½ 33ì  ê°ì  (PMV 3ì´ë©´ 0ì )
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    score += random.uniform(-5, 5)
    # ì ìˆ˜ ë²”ìœ„ ì œí•œ (0~100)
    score = max(0, min(100, score))

    # Feature ìˆœì„œ: [temp, humidity, precip_prob, wind_speed, temp_diff, warmth, breathability, water_res]
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise_temp = temp + random.normalvariate(0, 0.5)  # í‰ê·  0, í‘œì¤€í¸ì°¨ 0.5ë„ ì˜¤ì°¨
    noise_hum = humidity + random.normalvariate(0, 2.0)  # ìŠµë„ 2% ì˜¤ì°¨
    data.append([noise_temp, noise_hum, precip_prob, wind_speed, temp_diff, warmth, breathability, water_res, score])

# DataFrame ìƒì„±
columns = ['temp', 'humidity', 'precip_prob', 'wind_speed', 'temp_diff', 'warmth', 'breathability', 'water_res',
           'score']
df = pd.DataFrame(data, columns=columns)

X = df.drop('score', axis=1)
y = df['score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 4. Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ---
best_params = {
    'n_estimators': 557,
    'learning_rate': 0.016686714196678172,
    'num_leaves': 50,
    'max_depth': 9,
    'min_child_samples': 50,
    'objective': 'regression',
    'metric': 'rmse',
    'random_state': 42,
    'n_jobs': 4,
    'verbose': -1
}

print(f"ğŸš€ LightGBM Final í•™ìŠµ ì‹œì‘ (Best Params ì ìš©)")

model = LGBMRegressor(**best_params)
model.fit(X_train, y_train)

# --- 5. ìµœì¢… í‰ê°€ ---
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("="*40)
print(f"ğŸ† ìµœì¢… ëª¨ë¸ í‰ê·  ì˜¤ì°¨(MAE): {mae:.2f}ì ")
print(f"âœ… ê²°ì • ê³„ìˆ˜(R2) : {r2:.4f}")
print("="*40)


# êµì°¨ ê²€ì¦
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')
# neg_maeëŠ” ìŒìˆ˜ê°’ì´ë¯€ë¡œ ì–‘ìˆ˜ë¡œ ë³€í™˜
mae_scores = -cv_scores
print(f"âœ… êµì°¨ ê²€ì¦ í‰ê·  ì˜¤ì°¨(MAE): {mae_scores.mean():.2f}ì  (Â±{mae_scores.std():.2f})")

# --- 6. íŠ¹ì„± ì¤‘ìš”ë„ (Feature Importance) ---
importances = model.feature_importances_
feature_names = X.columns
sorted_idx = np.argsort(importances)[::-1]

print("-" * 30)
print("ğŸ” PMV ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ìƒê°í•œ ìš”ì†Œ (Top 3):")
for i in range(3):
    print(f"{i + 1}ìœ„: {feature_names[sorted_idx[i]]} (Score: {importances[sorted_idx[i]]:.1f})")
print("-" * 30)

# --- 7. í•™ìŠµ ê³¡ì„  (Scoring ë²„ê·¸ ìˆ˜ì •ë¨) ---
print("\nğŸ–¼ï¸ í•™ìŠµ ê³¡ì„ (Learning Curve) ìƒì„± ì¤‘...")
train_sizes, train_scores, valid_scores = learning_curve(
    model, X, y, cv=5,
    scoring='neg_mean_absolute_error', # [ìˆ˜ì •ë¨] accuracy -> neg_mae
    train_sizes=np.linspace(0.1, 1.0, 5)
)

# ìŒìˆ˜ MAEë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
train_mean = -np.mean(train_scores, axis=1)
valid_mean = -np.mean(valid_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color="purple", label="Training Error (MAE)")
plt.plot(train_sizes, valid_mean, 'o-', color="teal", label="Validation Error (MAE)")
plt.title("Learning Curve (Regression MAE) - Lower is Better") # ì œëª© ìˆ˜ì •
plt.xlabel("Training Examples")
plt.ylabel("Mean Absolute Error") # ì¶• ì´ë¦„ ìˆ˜ì •
plt.legend(loc="best")
plt.grid()

# ì €ì¥
current_dir = os.path.dirname(os.path.abspath(__file__))
artifacts_dir = os.path.join(current_dir, "..", "artifacts")
os.makedirs(artifacts_dir, exist_ok=True)
save_img_path = os.path.join(artifacts_dir, "learning_curve_regression.png")
plt.savefig(save_img_path)
print(f"   -> ì‹œê°í™” ì €ì¥ë¨: {save_img_path}")

# ëª¨ë¸ ì €ì¥
save_model_path = os.path.join(artifacts_dir, "weather_material_pmv.pkl")
joblib.dump(model, save_model_path)
print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_model_path}")