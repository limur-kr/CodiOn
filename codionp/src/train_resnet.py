# train_resnet.py
'''Train Resnet on fibre with PyTorch.'''
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torch.backends.cudnn as cudnn
import numpy as np
import matplotlib.pyplot as plt

import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
import torchvision.datasets as datasets
import torchvision.models as models

import os
import argparse
from PIL import Image, ImageFile
import time

# ğŸŒŸ [tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€] ğŸŒŸ
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True

# -------------------- [ë¼ë²¨ 9ê°€ì§€(8+Other) ì„¤ì • / ìµœì¢… ì •ë¦¬] --------------------

NEW_NUM_CLASSES = 9

# ìƒˆë¡œìš´ 9ê°œ í´ë˜ìŠ¤ ì´ë¦„ (0~8ë²ˆ)
NEW_CLASS_NAMES = [
    'Cotton',          # 0
    'Polyester',       # 1
    'Nylon',           # 2
    'Viscose/Rayon',   # 3
    'Acrylic',         # 4
    'Wool',            # 5
    'Lyocell/Modal',   # 6
    'Flax/Linen',      # 7
    'Other'            # 8 (ë‚˜ë¨¸ì§€ ëª¨ë“  ì†Œì¬)
]

# ì£¼ìš” ì†Œì¬ ë§¤í•‘ í…Œì´ë¸” (ë‚˜ë¨¸ì§€ëŠ” í•¨ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ 8ë²ˆìœ¼ë¡œ ì²˜ë¦¬í•¨)
SPECIFIC_MAPPING = {
    7: 0,             # cotton -> Cotton
    22: 1,            # polyester -> Polyester
    21: 2,            # nylon -> Nylon
    30: 3, 29: 3,     # viscose_rayon, acetate -> Viscose/Rayon
    1: 4,             # acrylic -> Acrylic
    31: 5,            # wool -> Wool
    17: 6, 19: 6, 8: 6, # lyocell, modal, cupro -> Lyocell/Modal
    10: 7             # flax_linen -> Flax/Linen
}


def remap_dataset_labels(dataset):
    """ImageFolder ë°ì´í„°ì…‹ì˜ ë¼ë²¨ì„ 9ê°œ(8ê°œ ì£¼ìš” + Other)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤."""
    print(f"Original classes: {len(dataset.classes)}. Starting remap to 9 classes...")

    new_samples = []
    # ë°ì´í„°ì…‹ì˜ ëª¨ë“  ìƒ˜í”Œì„ ìˆœíšŒí•˜ë©° ë¼ë²¨ ë³€ê²½
    for path, old_target in dataset.samples:
        # ì „ì—­ ë³€ìˆ˜ SPECIFIC_MAPPINGì„ ì§ì ‘ ì‚¬ìš©
        # ë§¤í•‘ í…Œì´ë¸”ì— ìˆìœ¼ë©´ í•´ë‹¹ ë²ˆí˜¸, ì—†ìœ¼ë©´ ë¬´ì¡°ê±´ 8ë²ˆ(Other)ìœ¼ë¡œ í• ë‹¹
        new_target = SPECIFIC_MAPPING.get(old_target, 8)
        new_samples.append((path, new_target))

    # ë°ì´í„°ì…‹ ì •ë³´ ì—…ë°ì´íŠ¸
    dataset.samples = new_samples
    dataset.targets = [s[1] for s in dataset.samples]
    dataset.classes = NEW_CLASS_NAMES

    # # ë””ë²„ê¹…ìš© ì¶œë ¥
    # max_idx = max(dataset.targets) if dataset.targets else 0
    # print(f"Remapping complete. Total samples: {len(dataset.samples)}. Max Label Index: {max_idx}")



# -------------------- [ìˆ˜ì •ëœ ì½”ë“œ ë¸”ë¡: CustomDataset] --------------------
# Windows MAX_PATH ì œí•œì„ ìš°íšŒí•˜ê¸° ìœ„í•œ CustomImageFolder
WINDOWS_MAX_PATH = 259


class CustomImageFolder(ImageFolder):
    def __init__(self, root, transform=None, target_transform=None, loader=None, is_valid_file=None):
        super().__init__(root, transform=transform, target_transform=target_transform, loader=loader,
                         is_valid_file=is_valid_file)

    def make_dataset(self, directory, class_to_idx, extensions=None, is_valid_file=None, allow_empty=False):
        instances = []
        directory = os.path.expanduser(directory)

        if class_to_idx is None:
            _, class_to_idx = self.find_classes(directory)

        if is_valid_file is None:
            if extensions is not None:
                def is_valid_file(x):
                    return x.lower().endswith(extensions)
            else:
                from torchvision.datasets.folder import IMG_EXTENSIONS
                def is_valid_file(x):
                    return x.lower().endswith(IMG_EXTENSIONS)

        for target_class in sorted(class_to_idx.keys()):
            class_index = class_to_idx[target_class]
            target_dir = os.path.join(directory, target_class)

            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):
                for fname in sorted(fnames):
                    path = os.path.join(root, fname)

                    if len(path) >= WINDOWS_MAX_PATH:
                        print(f"[Excluded] Path length exceeds {WINDOWS_MAX_PATH} limit: {path}")
                        continue

                    if is_valid_file(path):
                        instances.append((path, class_index))

        return instances


# ---------------------------------------------------------------------------------

# train_resnet.py (í´ë˜ìŠ¤ ì •ì˜ ì„¹ì…˜ ì¶”ê°€ 3ì°¨ ëª¨ë¸ë§ 251217)

class EarlyStopping:
    """Validation Lossê°€ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤."""
    def __init__(self, patience=40, verbose=False, delta=0):
        self.patience = patience    # ì°¸ì„ì„±: ì˜¤ì°¨ê°€ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ì§€ì¼œë³¼ ì—í­
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.inf
        self.delta = delta

    def __call__(self, val_loss):
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.counter = 0


# define input args
parser = argparse.ArgumentParser(description='PyTorch ResNet Training')
parser.add_argument('--lr', default=0.01, type=float, help='learning rate')
parser.add_argument('--resume', '-r', action='store_true',
                    help='resume from checkpoint')
parser.add_argument('--data', default='fibre', type=str,
                    help='dataset selection')
parser.add_argument('--batch_size', default=128, type=int,
                    help='batch size')
parser.add_argument('--num_classes', default=9, type=int,
                    help='number of classes')
parser.add_argument('--num_workers', default=2, type=int,
                    help='number of workers')
parser.add_argument('--data_parent_dir', default='../data', type=str,
                    help='parent directory of data')

# ëª¨ë¸ì˜ˆì¸¡[251215 ì¶”ê°€]
parser.add_argument('--predict_path', type=str, default=None,
                    help='path to a single image for prediction')

args = parser.parse_args()

DATA = args.data
base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
data_path = os.path.join(base_dir, 'data', DATA)

train_data = os.path.join(data_path, 'train')
test_data = os.path.join(data_path, 'test')

device = 'cuda' if torch.cuda.is_available() else 'cpu'
best_acc = 0
start_epoch = 0

# [251215 ì¶”ê°€] í•™ìŠµ ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
history = []

# Data
print('==> Preparing data..')

data_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    # --- [ê°•í™”ëœ ì¦ê°•ë²• ì¶”ê°€ 3ì°¨ ëª¨ë¸ë§ 251217] ---
    transforms.RandomRotation(15),           # Â±15ë„ ë¬´ì‘ìœ„ íšŒì „
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # ë°ê¸°, ëŒ€ë¹„ ë³€í™”
    # --------------------------
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

print(f"Train data path: {train_data}")
print(f"Test data path: {test_data}")

train_set = CustomImageFolder(root=train_data, transform=data_transform, loader=datasets.folder.pil_loader)
test_set = CustomImageFolder(root=test_data, transform=test_transform, loader=datasets.folder.pil_loader)

# â­â­ ë¼ë²¨ ì¬ë§µí•‘ í•¨ìˆ˜ í˜¸ì¶œ (ì¶”ê°€ëœ ë¶€ë¶„) â­â­
remap_dataset_labels(train_set)
remap_dataset_labels(test_set)
# -----------------------------------------------

train_loader = torch.utils.data.DataLoader(
    train_set, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)

test_loader = torch.utils.data.DataLoader(
    test_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)

# Model
print('==> Building model..')
#net = get_resnet18(args.num_classes)
net = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)
num_ftrs = net.fc.in_features
# --- [Dropout ì¶”ê°€ ë° ë¶„ë¥˜ê¸° ìˆ˜ì • 3ì°¨ ëª¨ë¸ë§ ì¶”ê°€ 251217] ---
net.fc = nn.Sequential(
    nn.Dropout(p=0.2),           # 20% í™•ë¥ ë¡œ ë‰´ëŸ°ì„ ë” (ê³¼ì í•© ë°©ì§€ í•µì‹¬)
    nn.Linear(num_ftrs, args.num_classes)
)
# -----------------------------------
net = net.to(device)

if device == 'cuda':
    # net = torch.nn.DataParallel(net)
    cudnn.benchmark = True

if args.resume:
    # Load checkpoint.
    print('==> Resuming from checkpoint..')
    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'
    # ê²½ê³  ë¬´ì‹œ ê´€ë ¨ ë©”ì‹œì§€ëŠ” ì´ì „ì— ë‚˜ì™”ìœ¼ë¯€ë¡œ ìƒëµí•©ë‹ˆë‹¤.
    checkpoint = torch.load('./checkpoint/latest_best.pth')
    net.load_state_dict(checkpoint['net'])
    best_acc = checkpoint['acc']
    start_epoch = checkpoint['epoch']

criterion = nn.CrossEntropyLoss()
# SGDì—ì„œ AdamWë¡œ ë³€ê²½
#optimizer = optim.SGD(net.parameters(), lr=args.lr,momentum=0.9, weight_decay=5e-4)

# AdamWì˜ í•™ìŠµë¥ ì€ SGDë³´ë‹¤ í›¨ì”¬ ì‘ì€ 1e-3 (0.001) ì •ë„ì—ì„œ ì‹œì‘í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
ADAMW_LR = 1e-3 # AdamWì— ì í•©í•œ í•™ìŠµë¥  (0.01ë³´ë‹¤ í›¨ì”¬ ì‘ìŠµë‹ˆë‹¤.)
ADAMW_WEIGHT_DECAY = 1e-2 # AdamWì˜ ì¼ë°˜ì ì¸ Weight Decay ê°’
optimizer = optim.AdamW(net.parameters(), lr=ADAMW_LR, weight_decay=ADAMW_WEIGHT_DECAY)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)


def topk(output, target, ks=(1,)):
    """Computes the precision@k for the specified values of k"""
    max_k = max(ks)
    batch_size = target.size(0)

    _, pred = output.topk(max_k, 1, True, True)
    pred = pred.t()
    correct = pred.eq(target.view(1, -1).expand_as(pred))

    res = []
    for k in ks:
        correct_k = correct[:k].reshape(-1).float().sum(0)
        res.append(correct_k.mul_(100.0 / batch_size))
    return res


# Training
def train(epoch):
    print('\nEpoch: %d' % epoch)
    model = net
    model.train()
    train_loss = 0
    correct = 0
    total = 0

    # ğŸŒŸ [tqdm ì ìš©] ğŸŒŸ
    # train_loaderë¥¼ tqdmìœ¼ë¡œ ê°ì‹¸ê³  ì„¤ëª…ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    train_bar = tqdm(train_loader, desc=f'Epoch {epoch} (Train)', unit='batch')

    for batch_idx, (inputs, targets) in enumerate(train_bar):

        try:
            inputs, targets = inputs.to(device), targets.to(device)
        except Exception as e:
            print(f"\n[Skipped] Batch {batch_idx + 1} due to device or data error: {e}")
            continue

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

        # ğŸŒŸ [tqdm.set_postfixë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  ë°”ì— ì •ë³´ í‘œì‹œ] ğŸŒŸ
        avg_loss = train_loss / (batch_idx + 1)
        acc_percent = 100. * correct / total

        train_bar.set_postfix(Loss=f'{avg_loss:.3f}', Acc=f'{acc_percent:.3f}% ({correct}/{total})')

    return avg_loss, acc_percent

    # ê¸°ì¡´ progress_bar í˜¸ì¶œ êµ¬ë¬¸ì€ ì‚­ì œí•©ë‹ˆë‹¤.


def test(epoch):
    global best_acc
    global history
    model = net
    model.eval()
    test_loss = 0
    correct = 0
    total = 0

    # ğŸŒŸ [tqdm ì ìš©] ğŸŒŸ
    # test_loaderë¥¼ tqdmìœ¼ë¡œ ê°ìŒ‰ë‹ˆë‹¤. leave=FalseëŠ” ì™„ë£Œ í›„ í‘œì‹œì¤„ì„ ì œê±°í•©ë‹ˆë‹¤.
    with torch.no_grad():
        test_bar = tqdm(test_loader, desc=f'Epoch {epoch} (Test) ', unit='batch', leave=False)
        for batch_idx, (inputs, targets) in enumerate(test_bar):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            # ğŸŒŸ [tqdm.set_postfixë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  ë°”ì— ì •ë³´ í‘œì‹œ] ğŸŒŸ
            avg_loss = test_loss / (batch_idx + 1)
            acc_percent = 100. * correct / total

            test_bar.set_postfix(Loss=f'{avg_loss:.3f}', Acc=f'{acc_percent:.3f}% ({correct}/{total})')

        # ê¸°ì¡´ progress_bar í˜¸ì¶œ êµ¬ë¬¸ì€ ì‚­ì œí•©ë‹ˆë‹¤.

    # Save checkpoint.
    acc = 100. * correct / total

    if acc > best_acc:
        print('Saving..')
        state = {
            'net': model.state_dict(),
            'acc': acc,
            'epoch': epoch,
        }
        if not os.path.isdir('checkpoint'):
            os.mkdir('checkpoint')

        # ğŸŒŸ [ìˆ˜ì •]: íŒŒì¼ëª…ì— ì •í™•ë„ì™€ ì—í­ì„ í¬í•¨í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
        filename = f'ckpt_epoch_{epoch}_acc_{acc:.2f}.pth'
        torch.save(state, os.path.join('./checkpoint', filename))

        # ğŸŒŸ [ì¶”ê°€]: ê¸°ì¡´ì˜ ìµœê³  ëª¨ë¸ íŒŒì¼ëª…ì„ ë®ì–´ì“°ëŠ” 'latest_best.pth'ë¥¼ ì¶”ê°€ë¡œ ì €ì¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
        torch.save(state, './checkpoint/latest_best.pth')
        best_acc = acc

        # ğŸŒŸ [ì¶”ê°€] test ê²°ê³¼ ë°˜í™˜
    return test_loss / len(test_loader), acc

# -------------------- [ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ í•¨ìˆ˜ ì¶”ê°€ / 251215 ì¶”ê°€] --------------------

def predict_single_image(image_path, model, transform, class_names):
    """ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ, ì˜ˆì¸¡í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(f"\n==> Predicting image: {image_path}")

    # 1. ì´ë¯¸ì§€ ë¡œë“œ
    try:
        img = Image.open(image_path).convert('RGB')
    except FileNotFoundError:
        print(f"[Error] Image file not found at: {image_path}")
        return
    except Exception as e:
        print(f"[Error] Could not load image: {e}")
        return

    # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    input_tensor = transform(img)
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (C, H, W) -> (1, C, H, W)
    input_batch = input_tensor.unsqueeze(0)

    # 3. ëª¨ë¸ ë¡œë“œ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
    checkpoint_path = './checkpoint/latest_best.pth'
    if not os.path.exists(checkpoint_path):
        print("[Error] Checkpoint not found. Please train the model first or check the path.")
        return

    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['net'])
    model.eval()
    print(f"Model loaded from epoch {checkpoint['epoch']} with best accuracy {checkpoint['acc']:.2f}%.")

    # 4. ì˜ˆì¸¡ ìˆ˜í–‰
    with torch.no_grad():
        input_batch = input_batch.to(device)
        output = model(input_batch)

    # 5. ê²°ê³¼ í•´ì„
    probabilities = F.softmax(output, dim=1)
    top_p, top_class_idx = probabilities.topk(5, dim=1)

    predicted_class_idx = top_class_idx[0, 0].item()
    predicted_class_name = class_names[predicted_class_idx]
    confidence = top_p[0, 0].item() * 100

    print(f"\n[Prediction Result]")
    print(f"Predicted Class: {predicted_class_name}")
    print(f"Confidence: {confidence:.2f}%")
    print("\nTop 5 Predictions:")
    for i in range(5):
        class_name = class_names[top_class_idx[0, i].item()]
        prob = top_p[0, i].item() * 100
        print(f"  {i+1}. {class_name} ({prob:.2f}%)")

# -------------------------------------------------------------------------

# -------------------- [Loss/Accuracy ì‹œê°í™” í•¨ìˆ˜ ì¶”ê°€] --------------------
def plot_history(history_data, save_path='./training_history.png'):
    """
    í•™ìŠµ ì´ë ¥(Train/Test Loss, Accuracy)ì„ ì‹œê°í™”í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    history_dataëŠ” [[epoch, train_loss, train_acc, test_loss, test_acc], ...] í˜•íƒœì…ë‹ˆë‹¤.
    """
    if not history_data:
        print("[Plot Error] No history data to plot.")
        return

    # Numpy ë°°ì—´ë¡œ ë³€í™˜ ë° ë°ì´í„° ì¶”ì¶œ
    history_array = np.array(history_data)
    epochs = history_array[:, 0]
    train_losses = history_array[:, 1]
    train_accuracies = history_array[:, 2]
    test_losses = history_array[:, 3]
    test_accuracies = history_array[:, 4]

    plt.figure(figsize=(15, 6)) # ì „ì²´ ê·¸ë¦¼ í¬ê¸° í™•ëŒ€

    # 1. Loss ê·¸ë˜í”„ (Train vs Test)
    plt.subplot(1, 2, 1) # 1í–‰ 2ì—´ ì¤‘ 1ë²ˆì§¸
    plt.plot(epochs, train_losses, label='Train Loss', color='blue')
    plt.plot(epochs, test_losses, label='Validation Loss', color='red', linestyle='--')
    plt.title('Loss over Epochs (Train vs Validation)')
    plt.xlabel('Epoch')
    plt.ylabel('Loss (CrossEntropy)')
    plt.legend()
    plt.grid(True)

    # 2. Accuracy ê·¸ë˜í”„ (Train vs Test)
    plt.subplot(1, 2, 2) # 1í–‰ 2ì—´ ì¤‘ 2ë²ˆì§¸
    plt.plot(epochs, train_accuracies, label='Train Accuracy', color='green')
    plt.plot(epochs, test_accuracies, label='Validation Accuracy', color='orange', linestyle='--')
    plt.title('Accuracy over Epochs (Train vs Validation)')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(save_path)
    print(f"\n[Visualization Complete] History saved to: {save_path}")
    plt.show()

# -------------------------------------------------------------------------


# ğŸŒŸ [if __name__ == '__main__': ë¸”ë¡ìœ¼ë¡œ í›ˆë ¨ ë£¨í”„ ê°ì‹¸ê¸°] ğŸŒŸ
# Windowsì—ì„œ num_workers > 0ìœ¼ë¡œ ì‹¤í–‰í•  ê²½ìš° ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
if __name__ == '__main__':
    # ì˜ˆì¸¡ ì¸ìê°€ ìˆë‹¤ë©´ í•™ìŠµ ëŒ€ì‹  ì˜ˆì¸¡ì„ ìˆ˜í–‰
    if args.predict_path:
        # ImageFolderì˜ classes ì†ì„±ìœ¼ë¡œ í´ë˜ìŠ¤ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        class_names = NEW_CLASS_NAMES

        # test_transformì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        predict_single_image(
            image_path=args.predict_path,
            model=net,
            transform=test_transform,
            class_names=class_names
        )
    else:
        # Early Stopping ì´ˆê¸°í™” (ì—¬ê¸°ì„œëŠ” 40ì—í­ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¢…ë£Œ)
        early_stopping = EarlyStopping(patience=15, verbose=True)

        # ì˜ˆì¸¡ ì¸ìê°€ ì—†ë‹¤ë©´ ê¸°ì¡´ëŒ€ë¡œ í•™ìŠµ ë£¨í”„ë¥¼ ì‹¤í–‰
        for epoch in range(start_epoch, start_epoch + 200):
            train_loss, train_acc = train(epoch)
            test_loss, test_acc = test(epoch)
            history.append([epoch, train_loss, train_acc, test_loss, test_acc])
            print(f"Epoch {epoch}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.2f}%, "
                  f"Test Loss = {test_loss:.4f}, Test Acc = {test_acc:.2f}%")

            scheduler.step()

            # --- [Early Stopping ì²´í¬ ì¶”ê°€ 3ì°¨ ëª¨ë¸ë§ 251217 ì¶”ê°€] ---
            early_stopping(test_loss)
            if early_stopping.early_stop:
                print("ğŸš© Early stopping triggered. Training stopped.")
                break
            # ----------------------------------

        # ğŸŒŸ [ì¶”ê°€] í•™ìŠµ ì™„ë£Œ í›„ ì‹œê°í™” í•¨ìˆ˜ í˜¸ì¶œ
        print("\n==> Training finished. Generating history plot...")
        plot_history(history)